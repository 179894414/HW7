```{r}
library(wordcloud)
library(ggplot2)
library(ggrepel)
```


```{r}
# Fill in the crime rates for 16 cities in a matrix
crime <- matrix(c(16.5,24.8,106,147,1112,905,494,
                  4.2,13.3,122,90,982,669,954,
                  11.6,24.7,340,242,808,609,645,
                  18.1,34.2,184,293,1668,901,602,
                  6.9,41.5,173,191,1534,1368,780,
                  13.0,35.7,477,220,1566,1183,788,
                  2.5,8.8,68,103,1017,724,468,
                  3.6,12.7,42,28,1457,1102,637,
                  16.8,26.6,289,186,1509,787,697,
                  10.8,43.2,255,226,1494,955,765,
                  9.7,51.8,286,355,1902,1386,862,
                  10.3,39.7,266,283,1056,1036,776,
                  9.4,19.4,522,267,1674,1392,848,
                  5.0,23.0,157,144,1530,1281,488,
                  5.1,22.9,85,148,1206,756,483,
                  12.5,27.6,524,217,1496,1003,739),nrow=16,ncol=7,byrow=TRUE)
```

```{r}
# Standardize the variables using the first method
crime_1 = matrix(NA,nrow=16,ncol=7)
for (i in 1:7) {
  col_mean = mean(crime[,i])
  col_sd = sd(crime[,i])
  crime_1[,i] = (crime[,i] - col_mean)/col_sd
} 
```

```{r}
# Calculate distances between each city
distances_1 = dist(crime_1,method="minkowski",p=2)

distances_1
```

```{r}
#Apply MDS: 1-dimensional
model_1_1 <- cmdscale(distances_1,k=1)
```

```{r}
#plot each city on 1-dimensional plot
model_1_1_df = as.data.frame(model_1_1)
model_1_1_df$city <- c("Atlanta","Boston","Chicago","Dallas","Denver","Detroit","Hartford","Honolulu","Houston","Kansas City","Los Angeles","New Orleans","New York","Portland","Tucson","Washington")

ggplot(model_1_1_df, aes(x = model_1_1_df[,1], y = 0,label = city)) +
  geom_point() +
  geom_text_repel(size=2, size=1, box.padding = unit(0.5, "lines"))
```

```{r}
#Apply MDS: 2-dimensional
model_1_2 <- cmdscale(distances_1,k=2)
```

```{r}
#plot each city on 2-dimensional plot
model_1_2_df = as.data.frame(model_1_2)
model_1_2_df$city <- c("Atlanta","Boston","Chicago","Dallas","Denver","Detroit","Hartford","Honolulu","Houston","Kansas City","Los Angeles","New Orleans","New York","Portland","Tucson","Washington")

ggplot(model_1_2_df, aes(x = model_1_2_df[,1], y = model_1_2_df[,2],label = city)) +
  geom_point() +
  geom_text_repel(size=4, size=1, box.padding = unit(0.5, "lines")) +
  xlim(-4,4) +
  ylim(-4,4)
```


```{r}
# Standardize the variables using the second method
crime_2 = matrix(NA,nrow=16,ncol=7)
for (i in 1:7) {
  col_min = min(crime[,i])
  col_max = max(crime[,i])
  crime_2[,i] = (crime[,i] - col_min) / (col_max - col_min)
} 
```

```{r}
# Calculate distances between each city
distances_2 = dist(crime_2,method="minkowski",p=2)

distances_2
```

```{r}
#Apply MDS: 1-dimensional
model_2_1 <- cmdscale(distances_2,k=1)
```

```{r}
#plot each city on 1-dimensional plot
model_2_1_df = as.data.frame(model_2_1)
model_2_1_df$city <- c("Atlanta","Boston","Chicago","Dallas","Denver","Detroit","Hartford","Honolulu","Houston","Kansas City","Los Angeles","New Orleans","New York","Portland","Tucson","Washington")

ggplot(model_2_1_df, aes(x = model_2_1_df[,1], y =0,label = city)) +
  geom_point() +
  geom_text_repel(size=2, size=1, box.padding = unit(0.5, "lines"))
```

```{r}
#Apply MDS: 2-dimensional
model_2_2 <- cmdscale(distances_2,k=2)
```

```{r}
#plot each city on 2-dimensional plot
model_2_2_df = as.data.frame(model_2_2)
model_2_2_df$city <- c("Atlanta","Boston","Chicago","Dallas","Denver","Detroit","Hartford","Honolulu","Houston","Kansas City","Los Angeles","New Orleans","New York","Portland","Tucson","Washington")

ggplot(model_2_2_df, aes(x = model_2_2_df[,1], y = model_2_2_df[,2],label = city)) +
  geom_point() +
  geom_text_repel(size=4, size=1, box.padding = unit(0.5, "lines")) +
  xlim(-1.5,1.5) +
  ylim(-1.5,1.5)
```
```{r}
#plot eigenvalues 
plot(cmdscale(distances_1,k=2,eig=TRUE)$eig, main="Eigenvalues of models",
  xlab="Index", ylab="Eigenvalues") 
```

```{r}
# Get GOF of 6 models
cmdscale(distances_1,k=1,eig=TRUE)$GOF

cmdscale(distances_2,k=1,eig=TRUE)$GOF

cmdscale(distances_1,k=2,eig=TRUE)$GOF

cmdscale(distances_2,k=2,eig=TRUE)$GOF

cmdscale(distances_1,k=3,eig=TRUE)$GOF

cmdscale(distances_2,k=3,eig=TRUE)$GOF
```

```{r}
# Get GOF values from 1000 1-dimensional models of 1000 random matrices 
# Create a vector to store 1000 GOF
GOF_1000_1 = c()
for (i in 1:1000) {
  GOF_1000_1[i] = cmdscale(dist(
  replicate(7,runif(16))),
  k=1,eig=TRUE)$GOF[1]
}

hist(GOF_1000_1,main="Histogram for GOF values from 1000 1d models", 
     xlab="GOF values")
max(GOF_1000_1)
min(GOF_1000_1)
mean(GOF_1000_1)
median(GOF_1000_1)
sd(GOF_1000_1)
```

```{r}
#get the probability that a value > 0.48 in an N(0.3108311, 0.03685708)
p_0.48 = pnorm(0.48, mean = 0.3108311, sd = 0.03685708, lower.tail = FALSE)
p_0.48
```

```{r}
# Get GOF values from 1000 two-dimensional models of 1000 random matrices 
# Create a vector to store 1000 GOF
GOF_1000 = c()
for (i in 1:1000) {
  GOF_1000[i] = cmdscale(dist(
  replicate(7,runif(16))),
  k=2,eig=TRUE)$GOF[1]
}

hist(GOF_1000)
max(GOF_1000)
min(GOF_1000)
mean(GOF_1000)
median(GOF_1000)
sd(GOF_1000)

#get the probability that a value > 0.683 in an N(0.5381184, 0.04177544)
p_0.683 = pnorm(0.683, mean = 0.5381184, sd = 0.04177544, lower.tail = FALSE)
p_0.683
```

```{r}
# Get GOF values from 1000 3-dimensional models of 1000 random matrices 
# Create a vector to store 1000 GOF
GOF_1000_3 = c()
for (i in 1:1000) {
  GOF_1000_3[i] = cmdscale(dist(
  replicate(7,runif(16))),
  k=3,eig=TRUE)$GOF[1]
}

hist(GOF_1000_3,main="Histogram for GOF values from 1000 3d random models", 
     xlab="GOF values")
max(GOF_1000_3)
min(GOF_1000_3)
mean(GOF_1000_3)
median(GOF_1000_3)
sd(GOF_1000_3)

#get the probability that a value > 0.82 in an N(0.7081695, 0.03726159)
p_0.82 = pnorm(0.82, mean = 0.7081695, sd = 0.03726159, lower.tail = FALSE)
p_0.82
```
```{r}
# percentage errors of the 1d model by first method of standardization:
d1_matrix = as.matrix(distances_1)
model_1 <- cmdscale(distances_1,k=1,eig=TRUE)
perc_error_1d = (d1_matrix - as.matrix(dist(model_1$points)))/d1_matrix
hist(perc_error_1d, main = "histogram of percentage errors of 1d model", xlab = "percentage errors")
perc_error_1d[is.na(perc_error_1d)] <- 0.3
max(perc_error_1d)
min(perc_error_1d)
mean(perc_error_1d)
median(perc_error_1d)
```

```{r}
# percentage errors of the 2d model by first method of standardization:
model_2 <- cmdscale(distances_1,k=2,eig=TRUE)
perc_error_2d = (d1_matrix - as.matrix(dist(model_2$points)))/d1_matrix
hist(perc_error_2d, main = "histogram of percentage errors of 2d model", xlab = "percentage errors")

perc_error_2d[is.na(perc_error_2d)] <- 0.3
max(perc_error_2d)
min(perc_error_2d)
mean(perc_error_2d)
median(perc_error_2d)
```

```{r}
# percentage errors of the 3d model by second method of standardization:
d2_matrix = as.matrix(distances_2)
model_3 <- cmdscale(distances_2,k=3,eig=TRUE)
perc_error_3d = (d2_matrix - as.matrix(dist(model_3$points)))/d2_matrix
hist(perc_error_3d,main = "histogram of percentage errors of 3d model", xlab = "percentage errors")
perc_error_3d[is.na(perc_error_3d)] <- 0.3
max(perc_error_3d)
min(perc_error_3d)
mean(perc_error_3d)
median(perc_error_3d)
```

```{r}
#Compare distance matrix for the models with the input distance matrix
#generate 1,2,3 dimensional models
model_11 <- cmdscale(distances_1,k=1)
model_12 <- cmdscale(distances_1,k=2)
model_13 <- cmdscale(distances_1,k=3)
plot(distances_1,dist(model_11))
plot(distances_1,dist(model_12))
plot(distances_1,dist(model_13))
```



```{r}
library(factoextra)
crime2 = as.data.frame(crime)
res.pca <- prcomp(crime2, scale = TRUE)
fviz_pca_biplot(res.pca, repel = TRUE,
                col.var = "#2E9FDF", # Variables color
                col.ind = "#696969"  # Individuals color
                )
```